{"cells":[{"cell_type":"markdown","metadata":{"id":"k3PKsz-1SH1U"},"source":["# Instructions\n","\n","For this assignment you will use PyTorch instead of EDF to implement and train neural networks. The experiments in this assignment will take a long time to run without a GPU, but you can run the notebook remotely on Google Colab and have access to GPUs for free -- in this case you don't have to worry about installing PyTorch as it is available by default in Google Colab's environment.\n","\n","To use Google Colab, you should access https://colab.research.google.com/ and upload this notebook to your workspace. To use a GPU, go to Edit -> Notebook settings and select GPU as the accelerator.\n","\n","In case you will be running the experiments in your own machine, you should install PyTorch -- there are multiple tutorials online and it is especially easy if you're using Anaconda. However, running on colab ensures that you are running in the same environment (e.g., same python version) that the homework was developed in.\n","\n","You can check out pytorch tutorials at https://pytorch.org/tutorials/."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FD0LkiPhSH1Z"},"outputs":[],"source":["import torch, math, copy\n","import numpy as np\n","from torchvision import datasets, transforms\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F"]},{"cell_type":"markdown","source":["loading the mnist data"],"metadata":{"id":"_gmEs9d3KAyW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_qmffSoSH1o","executionInfo":{"status":"ok","timestamp":1729439032436,"user_tz":300,"elapsed":11787,"user":{"displayName":"David McAllester","userId":"17534669777259640277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8eff1b3-e0b2-4211-ca11-04f6649ba7e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:07<00:00, 1280120.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 495689.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 4568512.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 5604745.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n","train_dataset = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST(\"data\", train=False, download=True, transform=transform)"]},{"cell_type":"markdown","metadata":{"id":"iIviUo83SH1o"},"source":["The pytorch works with modules which are instances of the class [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n","\n","A module class holds a parameter shape and a forward method. An instance of a module holds trainable parameters.  Creating an instance of a module allocates fresh parameters.  A module also includes a call method (automatically created) that allows an instance of the module to be applied like a function to an input.\n","\n","This is different from EDF.  In EDF the forward method accesses the input as an instance variable of the object rather than as an argument to an application of a module instance. A parameter package of EDF is somewhat analogous to a module instance in PyTorch.\n","\n","For the module class \"compose\" given below each instance of the module has instance variables f and g which are also modules.\n"]},{"cell_type":"code","source":["class compose(nn.Module):\n","  def __init__(self,f,g):\n","    super().__init__()\n","    self.f = f\n","    self.g = g\n","  def forward(self,input):\n","    return self.f(self.g(input))"],"metadata":{"id":"i54YGGCrRTIQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We now use compose to build networks.  This is somewhat non-standard but seems elegant.\n","\n","\n","\n"],"metadata":{"id":"s1yt06H9Wxea"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLJMTN4_z9Op"},"outputs":[],"source":["def simple_stack(depth,nchannels_in,nchannels_out,kernel_dim,activation):\n","  if(depth  == 1):\n","     return compose(activation,\n","                    nn.Conv2d(nchannels_in,\n","                              nchannels_out,\n","                              kernel_dim,\n","                              stride = 2,\n","                              padding = int(kernel_dim/2)))\n","  return compose(simple_stack(depth-1,nchannels_in,nchannels_out,kernel_dim,activation),\n","                 compose(activation,\n","                         nn.Conv2d(nchannels_in,\n","                         nchannels_in,\n","                         kernel_dim,\n","                         stride = 1,\n","                         padding = int(kernel_dim/2))))"]},{"cell_type":"markdown","source":["I also found an on-line discussion of initialization in PyTorch stating that \"The docs usually don’t mention the initialization method, but if you look at PyTorch’s source code, you can see the weights are initialized with Kaiming uniform initialization.\"\n","\n","This is called He initialization in the course slides (his name is Kaiming He). Xavier initialization is similar.\n","\n"],"metadata":{"id":"eYT3HpjbKiVD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xc9pl4t_SH1p"},"outputs":[],"source":["def PS2_CNN(stackdepth,kernel_dim,activation):\n","  #input.shape is [nbatch,28,28,1]\n","  u = compose(activation,nn.Conv2d(1, 4, kernel_dim, 2, 1))\n","  #u(input).shape = [nbatch,14,14,4]\n","  u = compose(simple_stack(stackdepth,4,8,kernel_dim,activation),u)\n","  #u(input).shape = [nbatch,7,7,8]\n","  u = compose(simple_stack(stackdepth,8,16,kernel_dim,activation),u)\n","  #u(input).shape = [nbatch,4,4,16]\n","  u = compose(simple_stack(stackdepth,16,32,kernel_dim,activation),u)\n","  #u(input).shape = [nbatch,2,2,32]\n","  u = compose(nn.Flatten(1),u);\n","  #u(input).shape = [nbatch,128]\n","  u = compose(nn.Linear(128,10),u)\n","  #u(input).shape = [nbatch,10]\n","  return u"]},{"cell_type":"code","source":["model = PS2_CNN(1,3,nn.ReLU())\n","\n","for p in model.parameters():\n","  print(p.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUsbKXLJopkn","executionInfo":{"status":"ok","timestamp":1729439073619,"user_tz":300,"elapsed":164,"user":{"displayName":"David McAllester","userId":"17534669777259640277"}},"outputId":"b1bcafbc-f717-46fa-94fd-39bb213b0d87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10, 128])\n","torch.Size([10])\n","torch.Size([32, 16, 3, 3])\n","torch.Size([32])\n","torch.Size([16, 8, 3, 3])\n","torch.Size([16])\n","torch.Size([8, 4, 3, 3])\n","torch.Size([8])\n","torch.Size([4, 1, 3, 3])\n","torch.Size([4])\n"]}]},{"cell_type":"code","source":["model = PS2_CNN(2,3,nn.ReLU())\n","\n","for p in model.parameters():\n","  print(p.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qhP-6md-rokN","executionInfo":{"status":"ok","timestamp":1729439112731,"user_tz":300,"elapsed":192,"user":{"displayName":"David McAllester","userId":"17534669777259640277"}},"outputId":"c26ef9d9-eb24-402a-88f9-f74a4d878d99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10, 128])\n","torch.Size([10])\n","torch.Size([32, 16, 3, 3])\n","torch.Size([32])\n","torch.Size([16, 16, 3, 3])\n","torch.Size([16])\n","torch.Size([16, 8, 3, 3])\n","torch.Size([16])\n","torch.Size([8, 8, 3, 3])\n","torch.Size([8])\n","torch.Size([8, 4, 3, 3])\n","torch.Size([8])\n","torch.Size([4, 4, 3, 3])\n","torch.Size([4])\n","torch.Size([4, 1, 3, 3])\n","torch.Size([4])\n"]}]},{"cell_type":"markdown","metadata":{"id":"0cTYkX0GSH1p"},"source":["Note that the module PS2_CNN does not have any activation after the fully-connected layer. The PyTorch loss module that is used for cross entropy loss takes logits (scores) as input rather than class probabilities."]},{"cell_type":"markdown","metadata":{"id":"rx_4tOu4uiFW"},"source":["We now provide a generic training algorithm for training a multiclass classification. Training minimizes cross entropy loss but we report classification error rate.\n","\n","Hyperparameters should be tuned on validation data and tested on test data not used in training or tuning.  Here we will cheat and use the test data as thought it were the validation data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIHugdT9SH1o"},"outputs":[],"source":["def vanilla_train(model, nepochs,learning_rate, momentum, nbatch,train_data,val_data):\n","\n","  #this function only uses the GPU while computing\n","  #the GPU is released when the computation is done\n","\n"," if torch.cuda.is_available():\n","  model = model.cuda() #we move the model parameters onto a GPU\n","\n","  print('training nbatch = {:03d},lr = {:.2f}, momentum = {:.2f}'.format(nbatch,learning_rate,momentum))\n","\n","  train_loader = torch.utils.data.DataLoader(train_data, batch_size=nbatch, shuffle=True)\n","  test_loader = torch.utils.data.DataLoader(val_data, batch_size=nbatch, shuffle=False)\n","  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n","\n","  for epoch in range(nepochs):\n","    train_err = train_epoch(model,optimizer, train_loader)\n","    test_err = test(model, test_loader)\n","    print('Epoch {:03d}/{:03d}, Train Error {:.2f}% || Test Error {:.2f}%'.format(epoch+1, nepochs, train_err*100, test_err*100))\n","\n","\n","\n","def train_epoch(model, optimizer,loader):\n","    total_correct = 0.\n","    total_samples = 0.\n","\n","    for batch_idx, (data, target) in enumerate(loader):\n","      #the loader organizes the data and target into batches\n","      #the GPU holds one batch at a time.\n","      if torch.cuda.is_available():\n","        data, target = data.cuda(), target.cuda()\n","      output = model(data)\n","      # The error rate is determined by the logits -- we do not yet need the loss.\n","      total_correct += (output.argmax(1) == target).type(torch.float).sum().item()\n","      total_samples += len(data)\n","\n","      loss = nn.CrossEntropyLoss()(output, target)\n","      loss.backward()\n","\n","      #print('Batch {:04}, Train Error {:03}%'.format(batch_idx, 100*(1-total_correct/total_samples)))\n","      optimizer.step()\n","      optimizer.zero_grad()\n","\n","    return 1 - total_correct/total_samples\n","\n","def test(model, loader):\n","    total_correct = 0.\n","    total_samples = 0.\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(loader):\n","          if torch.cuda.is_available():\n","              data, target = data.cuda(), target.cuda()\n","          output = model(data)\n","          total_correct += (output.argmax(1) == target).type(torch.float).sum().item()\n","          total_samples += len(data)\n","    return 1 - total_correct/total_samples"]},{"cell_type":"markdown","source":["After some exploration we can find a simple learning rate schedule that seems to work well for batch size 16 and momentum zero.  The following two cells show the variability in the stochastic runs."],"metadata":{"id":"P8oyajiChLwD"}},{"cell_type":"code","source":["model = PS2_CNN(1,3,nn.ReLU())#intializes model parameters\n","vanilla_train(model, 2, .07, 0, 16, train_dataset, test_dataset)\n","vanilla_train(model, 3, .01, 0, 16, train_dataset, test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729455188228,"user_tz":300,"elapsed":116189,"user":{"displayName":"David McAllester","userId":"17534669777259640277"}},"outputId":"306f3ac3-3064-4472-e9d7-91423cc4c17e","id":"vI1FTVFyiZJQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training nbatch = 016,lr = 0.07, momentum = 0.00\n","Epoch 001/002, Train Error 12.82% || Test Error 4.71%\n","Epoch 002/002, Train Error 3.18% || Test Error 2.49%\n","training nbatch = 016,lr = 0.01, momentum = 0.00\n","Epoch 001/003, Train Error 1.69% || Test Error 1.94%\n","Epoch 002/003, Train Error 1.45% || Test Error 1.67%\n","Epoch 003/003, Train Error 1.31% || Test Error 1.74%\n"]}]},{"cell_type":"code","source":["model = PS2_CNN(1,3,nn.ReLU())#intializes model parameters\n","vanilla_train(model, 2, .07, 0, 16, train_dataset, test_dataset)\n","vanilla_train(model, 3, .01, 0, 16, train_dataset, test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729455402231,"user_tz":300,"elapsed":117806,"user":{"displayName":"David McAllester","userId":"17534669777259640277"}},"outputId":"7a4271d6-20ff-4bcf-9c55-2d0a4c329297","id":"nmL14PB0frIh"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training nbatch = 016,lr = 0.07, momentum = 0.00\n","Epoch 001/002, Train Error 10.60% || Test Error 2.98%\n","Epoch 002/002, Train Error 3.20% || Test Error 2.79%\n","training nbatch = 016,lr = 0.01, momentum = 0.00\n","Epoch 001/003, Train Error 1.75% || Test Error 1.83%\n","Epoch 002/003, Train Error 1.53% || Test Error 1.72%\n","Epoch 003/003, Train Error 1.40% || Test Error 1.63%\n"]}]},{"cell_type":"markdown","source":["See if you can find comparable performance over five epochs for barch size 64 and momentum zero. Also find a schedule that works well for batch size 16 and momentum .75.  You should be able to make a good first guess in each case.\n","\n","**** your solution goes below ****"],"metadata":{"id":"ayfDdlXOhn0M"}},{"cell_type":"markdown","source":["**** Your solution goes above ****\n","\n","We now consider increasing the depth of the network.  The following network has nine convolution layers.  It does not seem possible to find a learning rate that works well. (The test error 88.65% comes up a lot.  I'm guessing that is the random guessing error rate on the test data where the test data is not exactly unifromly distributed over the labels.)"],"metadata":{"id":"6gZumP0olSlS"}},{"cell_type":"code","source":["model = PS2_CNN(3,3,nn.ReLU())\n","vanilla_train(model, 2, .3, 0, 64, train_dataset, test_dataset)\n","vanilla_train(model, 3, .07, 0, 64, train_dataset, test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729455879147,"user_tz":300,"elapsed":91327,"user":{"displayName":"David McAllester","userId":"17534669777259640277"}},"outputId":"a9a29a63-c496-4f0c-caa0-55f64a42583f","id":"JPH6PHCvfRL2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training nbatch = 064,lr = 0.30, momentum = 0.00\n","Epoch 001/002, Train Error 89.03% || Test Error 88.65%\n","Epoch 002/002, Train Error 89.02% || Test Error 88.65%\n","training nbatch = 064,lr = 0.07, momentum = 0.00\n","Epoch 001/003, Train Error 88.78% || Test Error 88.65%\n","Epoch 002/003, Train Error 88.77% || Test Error 88.65%\n","Epoch 003/003, Train Error 88.77% || Test Error 88.65%\n"]}]},{"cell_type":"markdown","source":["You should now modify the nine layer network in the last cell to have a residual connection around each convolution layer. For the residual connections that require shape adjustment you can use the pytorch modules nn.avg_pool2d and F.pad. The package F contains functions with no trainable parameters.  See if you can find hyper-parameters for which the network trains.\n","\n","*** your solution goes below ***"],"metadata":{"id":"WIIeocc2oif-"}},{"cell_type":"markdown","source":["*** your solution goes above ***\n","\n","Finally replace each addition in the residual connection with a convex combination with a trainable combination weight.  This is an experiemnt -- I'm not sure what to expect.\n","\n","*** your solution goes below ***"],"metadata":{"id":"DmjUVgYUr-Y0"}}],"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"gpuType":"A100","provenance":[{"file_id":"18xicz66YkSX3_Ldr6a0NYkGkZl4xixi5","timestamp":1729458567714}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}